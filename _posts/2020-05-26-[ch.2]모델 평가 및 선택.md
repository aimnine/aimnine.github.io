---
title: "[예제로 공부하는 단단한 머신러닝] chapter 02. 모델 평가 및 선택"
date: 2020-05-26 00:00:00 -0400
categories: MachineLearning
---

# 2.1 경험 오차 및 과적합
- 오차율(error rate, E) : 잘못 분류한 샘플 수(a) / 전체 샘플 수(m)
- 정밀도(accuracy) : 1 - a/m = 1 - E
- 오차(error) : 실제 예측값과 샘플의 실제 값 사이의 차이
- 훈련 오차(training error) 혹은 경험 오차(empirical error) : 학습기가 훈련 세트상에서 만들어낸 오차
- 일반화 오차(generalization error) : 학습기가 새로운 샘플에서 만들어낸 오차

(대부분) 머신러닝의 목적은 일반화 오차가 가장 적은 학습기(모델)을 만들어 내는 것이다. 하지만, 우리는 새로운 데이터(실제 데이터)에 대해서 알 수 없고, 할 수 있는 것은 훈련 세트를 이용해서 경험 오차를 최대한 줄이는 것이다.

새로운 데이터에서 훌륭한 성능을 내는 모델을 만들기 위해, 우리는 훈련 데이터에서 잠재적인 '보편 규칙'을 찾아내어 모델을 학습시켜야 한다.

- 과적합(overfitting) : 훈련데이터'만'의 특징을 학습하여 훈련 오차는 낮지만, 일반화 성능이 떨어지는 상태
- 과소적합(underfitting) : 훈련데이터의 특징도 제대로 학습하지 못해 훈련 오차가 큰 상태

과적합이 일어나는 이유는 다양하다. (책에서는) 학습능력이 너무 뛰어나 훈련 데이터로부터 일반적이지 않은 특징까지 학습하는 경우가 가장 흔하다고 한다. 그 외에 과적합이 일어나는 경우는, 훈련 데이터가 실제 데이터와 다를 때(훈련 데이터가 분포를 충분히 포함하지 않을 때?) 혹은 훈련을 너무 오래 시켰을 때 등이 있을 것 같다.

과소적합의 경우, 과적합과 반대로 훈련을 충분히 시키지 않았거나 모델의 학습능력이 부족해서 발생하곤 한다.

대부분의 머신러닝 문제의 경우, 과소적합보다는 과적합을 방지하기 위해 여러가지 조치를 취해서 과적합의 정도를 최소화하려고 노력한다.

학습 알고리즘을 고르고, 일정한 파라미터를 선정하여 학습을 진행하여 모델을 얻고나면, 얻어진 모델들 중 어떤 것을 사용할 것 인가? 에 대한 고민을 하게된다. 이러한 과정을 **모델 선택**(model selection) 문제라고 한다. 일반화 오차를 측정할 수 있다면, 이를 이용해서 모델을 선택하면 될텐데, 일반적인 상황에서 일반화 오차는 측정할 수 없으므로 모델을 평가하기 위한 방법을 모색해야 한다.

# 2.2 평가 방법
평가는 테스트 세트(testing set)를 사용해서 진행된다. 테스트 세트는 훈련에 사용되지 않은(않도록 한) 데이터들로, 실제 샘플과 동일한 분포로 가정하여 테스트 세트를 이용해 측정한 테스트 오차(testing error)를 측정한다. 측정된 테스트 오차는 일반화 오차의 근사치로 추정한다.

즉, 의미있는 평가를 진행하기 위해서는 전체 데이터 세트에서 훈련 세트와 테스트 세트를 잘 나누는 것이 중요하다.

## 2.2.1 홀드아웃
홀드아웃(hold-out) 방법(검증 세트 기법)은 데이터 세트를 겹치지 않는 두 집단으로 나눠서, 하나를 훈련 세트(S) 다른 하나를 테스트 세트(T)로 사용하는 방법이다.

주의해야 할 점은 훈련 세트와 테스트 세트를 나눌 때, 되도록 데이터 분포가 같게 나눠야 한다. 잘못된 구분은 각 세트에 대한 편향을 가지게 할 수 있기 때문이다. 또한, 훈련/테스트 비율을 선정하는 것 역시 중요하다.

임의로 나누어진 훈련/테스트 세트는 나눠서 학습을 진행할 때마다 모델의 학습과 평가 결과가 다를 수 있기 때문에(훈련/테스트 데이터 분포가 매번 달라질 수 있기 때문에), 여러번 수행하여 학습 결과를 검증하는 것이 중요하다.

## 2.2.2 교차 검증
교차 검증(cross validation)은 데이터 세트를 중복하지 않는 k개의 집합으로 나눈 뒤, k-1개를 학습 세트로 사용하고 나머지 하나를 테스트 세트로 사용하는 방법이다. 이렇게 하면, k번의 훈련과 테스트가 가능하고, 결과값의 평균을 이용하여 검증을 할 수 있다. 이러한 방식은 k의 값에 따라 안정성과 정확도가 달라지는데, 이를 k겹 교차 검증(k-fold cross validation)이라고 부른다. 보통은 k값에 5, 10 등의 숫자를 자주 사용한다.

k 값이 커지면, 훈련과 테스트에 사용되는 연산량이 많이 필요하기 때문에 적절한(?) 숫자를 선택하는 것이 필요하다.

## 2.2.3 부트스트래핑
부트스트래핑(bootstrapping)은 부트스트랩 샘플링(bootstrap sampling)에 기반을 둔 샘플 추출 기법으로, 중복 추출을 허용하여 전체 데이터 세트에서 m만큼 데이터를 뽑아내서 데이터 세트를 만드는 방식이다. 이 방식으로 추출된 데이터를 학습에 사용하고, 나머지 데이터를 테스트에 사용하는 방식을 Out-of-Bag 예측이라고 한다.

부트스트래핑은 데이터 세트가 비교적 적거나, 훈련/테스트 세트로 분류하기 힘들때 사용하기 좋다. 또, 데이터 세트에서 다양한 (분포를 가지는) 훈련 세트를 만들 수 있기 때문에, 앙상블 기법에 적용하기 좋다.

하지만, 데이터가 충분하다면 일반적으로 홀드 아웃이나 교차 검증 방법을 사용한다.

## 2.2.4 파라미터 튜닝과 최종 모델
