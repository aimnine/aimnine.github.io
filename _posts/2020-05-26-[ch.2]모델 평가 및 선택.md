---
title: "[예제로 공부하는 단단한 머신러닝] chapter 02. 모델 평가 및 선택"
date: 2020-05-26 00:00:00 -0400
categories: MachineLearning
---

# 2.1 경험 오차 및 과적합
- 오차율(error rate, E) : 잘못 분류한 샘플 수(a) / 전체 샘플 수(m)
- 정밀도(accuracy) : 1 - a/m = 1 - E
- 오차(error) : 실제 예측값과 샘플의 실제 값 사이의 차이
- 훈련 오차(training error) 혹은 경험 오차(empirical error) : 학습기가 훈련 세트상에서 만들어낸 오차
- 일반화 오차(generalization error) : 학습기가 새로운 샘플에서 만들어낸 오차

(대부분) 머신러닝의 목적은 일반화 오차가 가장 적은 학습기(모델)을 만들어 내는 것이다. 하지만, 우리는 새로운 데이터(실제 데이터)에 대해서 알 수 없고, 할 수 있는 것은 훈련 세트를 이용해서 경험 오차를 최대한 줄이는 것이다.

새로운 데이터에서 훌륭한 성능을 내는 모델을 만들기 위해, 우리는 훈련 데이터에서 잠재적인 '보편 규칙'을 찾아내어 모델을 학습시켜야 한다.

- 과적합(overfitting) : 훈련데이터'만'의 특징을 학습하여 훈련 오차는 낮지만, 일반화 성능이 떨어지는 상태
- 과소적합(underfitting) : 훈련데이터의 특징도 제대로 학습하지 못해 훈련 오차가 큰 상태

과적합이 일어나는 이유는 다양하다. (책에서는) 학습능력이 너무 뛰어나 훈련 데이터로부터 일반적이지 않은 특징까지 학습하는 경우가 가장 흔하다고 한다. 그 외에 과적합이 일어나는 경우는, 훈련 데이터가 실제 데이터와 다를 때(훈련 데이터가 분포를 충분히 포함하지 않을 때?) 혹은 훈련을 너무 오래 시켰을 때(validation data의 필요성) 등이 있을 것 같다.

과소적합의 경우, 과적합과 반대로 훈련을 충분히 시키지 않았거나 모델의 학습능력이 부족해서 발생하곤 한다.

대부분의 머신러닝 문제의 경우, 과소적합보다는 과적합을 방지하기 위해 여러가지 조치를 취해서 과적합의 정도를 최소화하려고 노력한다.

학습 알고리즘을 고르고, 일정한 파라미터를 선정하여 학습을 진행하여 모델을 얻고나면, 얻어진 모델들 중 어떤 것을 사용할 것 인가? 에 대한 고민을 하게된다. 이러한 과정을 **모델 선택**(model selection) 문제라고 한다. 일반화 오차를 측정할 수 있다면, 이를 이용해서 모델을 선택하면 될텐데, 일반적인 상황에서 일반화 오차는 측정할 수 없으므로 모델을 평가하기 위한 방법을 모색해야 한다.

